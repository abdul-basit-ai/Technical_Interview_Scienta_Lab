{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook implements a Transformer-based architecture (\"GeneBERT\") to classify biological samples based on their gene expression profiles. Unlike traditional machine learning models (SVM, Random Forest), this approach leverages deep learning to capture complex, non-linear interactions within high-dimensional genetic data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gBLucYscAsDL",
        "outputId": "37a587a2-38da-43d6-cef1-01f1ae2873a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from opendatasets) (8.3.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Preprocessing: Out-of-Core Data Alignment\n",
        "\n",
        "The following code block performs the ETL (Extract, Transform, Load) process to create the final **(merged_gene_data.csv)**. Given the high dimensionality of genomic data, loading all datasets simultaneously would likely exceed Google Colab's available RAM. To mitigate this, we utilize an **out-of-core** processing strategy with the following specific techniques:\n",
        "\n",
        "1.  **Global Feature Alignment:**\n",
        "    We first perform a lightweight scan of all files to identify the **union** of all gene IDs. This ensures that every sample in the final dataset has the exact same feature columns, regardless of which file it originated from.\n",
        "\n",
        "2.  **Sparse Reindexing:**\n",
        "    When processing individual files, we use `.reindex()` to align the local samples to the global master gene list. Any missing gene values are filled with `0.0` (zero-padding), preserving the structural integrity of the matrix.\n",
        "\n",
        "3.  **Memory Optimization:**\n",
        "    * **Incremental Write:** Instead of concatenating DataFrames in RAM, we append chunks to the disk (`mode='a'`) and immediately release memory using `gc.collect()`.\n",
        "    * **Type Downcasting:** Data is converted to `float32` (single precision). This is sufficient for normalized gene counts and **halves the memory footprint** compared to the default `float64`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKSxSqOYAot6",
        "outputId": "a4832f04-6390-4054-bc41-b7e7d2849383"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: abdulbasit20062002\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/abdulbasit20062002/train-scienta-lab-interview-project\n",
            "Downloading train-scienta-lab-interview-project.zip to ./train-scienta-lab-interview-project\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128M/128M [00:00<00:00, 1.39GB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Phase 1: Scanning files to build Master Gene List...\n",
            "Total Unique Genes: 3221\n",
            "Phase 2: Processing and Appending files...\n",
            "  > Processing healthy_train_data.tsv...\n",
            "  > Processing ra_train_data.tsv...\n",
            "  > Processing sle_train_data.tsv...\n",
            "\n",
            "========================================\n",
            "FINAL DATA REPORT (Memory Efficient Mode)\n",
            "========================================\n",
            "1. Final Input Dimension (Genes):   3221\n",
            "2. Total Samples (Batch Size):      99785\n",
            "3. Data Sparsity (Zeros %):         88.13%\n",
            "4. Value Range:                     0.00 to 852100.00\n",
            "5. Class Distribution:\n",
            "   - Class 0 (Healthy): 24403\n",
            "   - Class 1 (RA):      37691\n",
            "   - Class 2 (SLE):     37691\n",
            "========================================\n",
            "Data successfully saved to: merged_gene_data.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import opendatasets as od\n",
        "import gc  \n",
        "\n",
        "dataset_url = 'https://www.kaggle.com/datasets/abdulbasit20062002/train-scienta-lab-interview-project'\n",
        "try:\n",
        "    od.download(dataset_url)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "DATA_PATH = './train-scienta-lab-interview-project'\n",
        "OUTPUT_FILE = 'merged_gene_data.csv'\n",
        "\n",
        "\n",
        "def memory_efficient_merge(path, output_filename):\n",
        "    files = glob.glob(os.path.join(path, '*.tsv'))\n",
        "\n",
        "    #  Build Master Gene List (Lightweight Scan) ---\n",
        "    print(\"Phase 1: Scanning files to build Master Gene List...\")\n",
        "    all_genes_set = set()\n",
        "    for f in files:\n",
        "        try:\n",
        "            # Read only the index (Gene Names)\n",
        "            df_iter = pd.read_csv(f, sep='\\t', index_col=0, usecols=[0])\n",
        "            all_genes_set.update(df_iter.index.tolist())\n",
        "            del df_iter\n",
        "            gc.collect()\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping {f} due to error: {e}\")\n",
        "\n",
        "    master_gene_list = sorted(list(all_genes_set))\n",
        "    num_genes = len(master_gene_list)\n",
        "    print(f\"Total Unique Genes: {num_genes}\")\n",
        "\n",
        "    # Initialize Output CSV \n",
        "    # We write the Header row first\n",
        "    # Header: Gene1, Gene2, ... GeneN, label\n",
        "    header = master_gene_list + ['label']\n",
        "    pd.DataFrame(columns=header).to_csv(output_filename, index=True, index_label=\"sample_id\")\n",
        "\n",
        "    #  Stream Processing (One File at a Time) ---\n",
        "    print(\"Phase 2: Processing and Appending files...\")\n",
        "\n",
        "    # Variables for Global Stats\n",
        "    global_max = -np.inf\n",
        "    global_min = np.inf\n",
        "    total_zeros = 0\n",
        "    total_elements = 0\n",
        "    class_counts = {0: 0, 1: 0, 2: 0}\n",
        "    total_samples = 0\n",
        "\n",
        "    for f in files:\n",
        "        fname = os.path.basename(f)\n",
        "        print(f\"  > Processing {fname}...\")\n",
        "\n",
        "        try:\n",
        "            # 1. Load Data\n",
        "            df = pd.read_csv(f, sep='\\t', index_col=0).T # Rows=Samples\n",
        "\n",
        "            # 2. Determine Label\n",
        "            if \"healthy\" in fname.lower():\n",
        "                label = 0\n",
        "            elif \"ra_\" in fname.lower():\n",
        "                label = 1\n",
        "            elif \"sle_\" in fname.lower():\n",
        "                label = 2\n",
        "            else:\n",
        "                print(f\"    WARNING: Skipping {fname} (Unknown Class)\")\n",
        "                continue\n",
        "\n",
        "            #  Align Columns (Zero Padding)\n",
        "            # Efficient Reindex\n",
        "            df = df.reindex(columns=master_gene_list, fill_value=0.0)\n",
        "\n",
        "            #  MEMORY TRICK: Downcast to Float32 (Saves 50% RAM)\n",
        "            df = df.astype('float32')\n",
        "\n",
        "            #  Add Label\n",
        "            df['label'] = label\n",
        "\n",
        "            #  Update Stats (On the fly)\n",
        "            current_vals = df.drop(columns=['label']).values\n",
        "            global_max = max(global_max, np.nanmax(current_vals))\n",
        "            global_min = min(global_min, np.nanmin(current_vals))\n",
        "            total_zeros += (current_vals == 0).sum()\n",
        "            total_elements += current_vals.size\n",
        "            class_counts[label] += len(df)\n",
        "            total_samples += len(df)\n",
        "\n",
        "            # Append to Disk immediately\n",
        "            # mode='a' (append), header=False (header already written)\n",
        "            df.to_csv(output_filename, mode='a', header=False)\n",
        "\n",
        "            #  Clean up RAM immediately\n",
        "            del df\n",
        "            del current_vals\n",
        "            gc.collect()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {fname}: {e}\")\n",
        "\n",
        "    return {\n",
        "        \"num_genes\": num_genes,\n",
        "        \"num_samples\": total_samples,\n",
        "        \"sparsity\": total_zeros / total_elements if total_elements > 0 else 0,\n",
        "        \"min_val\": global_min,\n",
        "        \"max_val\": global_max,\n",
        "        \"class_counts\": class_counts\n",
        "    }\n",
        "\n",
        "\n",
        "stats = memory_efficient_merge(DATA_PATH, OUTPUT_FILE)\n",
        "\n",
        "if stats:\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"FINAL DATA REPORT (Memory Efficient Mode)\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"1. Final Input Dimension (Genes):   {stats['num_genes']}\")\n",
        "    print(f\"2. Total Samples (Batch Size):      {stats['num_samples']}\")\n",
        "    print(f\"3. Data Sparsity (Zeros %):         {stats['sparsity']:.2%}\")\n",
        "    print(f\"4. Value Range:                     {stats['min_val']:.2f} to {stats['max_val']:.2f}\")\n",
        "    print(f\"5. Class Distribution:\")\n",
        "    print(f\"   - Class 0 (Healthy): {stats['class_counts'].get(0, 0)}\")\n",
        "    print(f\"   - Class 1 (RA):      {stats['class_counts'].get(1, 0)}\")\n",
        "    print(f\"   - Class 2 (SLE):     {stats['class_counts'].get(2, 0)}\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Data successfully saved to: {OUTPUT_FILE}\")\n",
        "else:\n",
        "    print(\"Merge failed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \"GeneBERT\" Architecture\n",
        "\n",
        "We adapt the Transformer architecture for tabular data:\n",
        "\n",
        "Feature Projection: A Linear layer projects the high-dimensional input (genes) into a dense embedding space (128 dim).\n",
        "\n",
        "Transformer Encoder: We utilize nn.TransformerEncoder. While Transformers are typically used for sequences (like text), applying them here allows the model to learn complex representations via self-attention mechanisms and feed-forward networks with residual connections.\n",
        "\n",
        "Classification Head: A final MLP projects the learned representations to the number of target classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cItXjA_sF0pc",
        "outputId": "51d72b44-2ef3-4232-e9ae-78c91b732871"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Loading Data Safely (Chunk by Chunk) ---\n",
            "  Processed chunk 0...\n",
            "  Processed chunk 5...\n",
            "  Processed chunk 10...\n",
            "  Processed chunk 15...\n",
            "\n",
            "Data Loaded Successfully!\n",
            "Shape: (99785, 3222)\n",
            "--- Preprocessing ---\n",
            "Scaler saved.\n",
            "Model initialized on cuda\n",
            "\n",
            "--- Starting Training ---\n",
            "Epoch 1/10 | Loss: 0.3939 | Val Acc: 83.39%\n",
            "Epoch 2/10 | Loss: 0.3255 | Val Acc: 85.53%\n",
            "Epoch 3/10 | Loss: 0.3121 | Val Acc: 87.68%\n",
            "Epoch 4/10 | Loss: 0.3007 | Val Acc: 76.16%\n",
            "Epoch 5/10 | Loss: 0.2899 | Val Acc: 88.01%\n",
            "Epoch 6/10 | Loss: 0.2897 | Val Acc: 81.54%\n",
            "Epoch 7/10 | Loss: 0.2983 | Val Acc: 86.55%\n",
            "Epoch 8/10 | Loss: 0.2802 | Val Acc: 84.75%\n",
            "Epoch 9/10 | Loss: 0.2831 | Val Acc: 85.52%\n",
            "Epoch 10/10 | Loss: 0.2861 | Val Acc: 79.79%\n",
            "Model saved successfully.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "\n",
        "# Config\n",
        "FILE_PATH = \"merged_gene_data.csv\"\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-4\n",
        "EPOCHS = 10\n",
        "EMBED_DIM = 128\n",
        "NUM_HEADS = 4\n",
        "NUM_LAYERS = 2\n",
        "NUM_CLASSES = 3\n",
        "\n",
        "# Data Loading\n",
        "print(\"--- Loading Data Safely (Chunk by Chunk) ---\")\n",
        "\n",
        "chunks = []\n",
        "# We read 5000 rows at a time to prevent RAM explosion\n",
        "loader = pd.read_csv(FILE_PATH, index_col=0, chunksize=5000)\n",
        "\n",
        "for i, chunk in enumerate(loader):\n",
        "    # 1. Optimize Memory: Convert Genes to float32\n",
        "    # (We drop 'label' temporarily to convert everything else)\n",
        "    labels = chunk['label']\n",
        "    features = chunk.drop(columns=['label']).astype('float32')\n",
        "\n",
        "    # 2. Optimize Labels: Convert to int8 (extremely small)\n",
        "    features['label'] = labels.astype('int8')\n",
        "\n",
        "    chunks.append(features)\n",
        "    if i % 5 == 0:\n",
        "        print(f\"  Processed chunk {i}...\")\n",
        "\n",
        "# Combine all chunks\n",
        "df = pd.concat(chunks)\n",
        "del chunks\n",
        "gc.collect()\n",
        "\n",
        "print(f\"\\nData Loaded Successfully!\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "\n",
        "# Separate X and y\n",
        "# Note: We use .values to get numpy arrays immediately\n",
        "y = df['label'].values\n",
        "X = df.drop(columns=['label']).values\n",
        "\n",
        "# Free up the dataframe\n",
        "del df\n",
        "gc.collect()\n",
        "\n",
        "#Pre Processing\n",
        "print(\"--- Preprocessing ---\")\n",
        "\n",
        "# Log-Normalization\n",
        "# We use np.log1p which works safely on float32\n",
        "X = np.log1p(X)\n",
        "\n",
        "#  Train/Validation Split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "\n",
        "# Save Scaler\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "print(\"Scaler saved.\")\n",
        "\n",
        "\n",
        "# DATALOADER\n",
        "\n",
        "class GeneDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
        "\n",
        "train_loader = DataLoader(GeneDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(GeneDataset(X_val, y_val), batch_size=BATCH_SIZE)\n",
        "\n",
        "# Model\n",
        "class GeneBERT(nn.Module):\n",
        "    def __init__(self, input_dim, embed_dim, num_heads, num_layers, num_classes):\n",
        "        super(GeneBERT, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Sequential(\n",
        "            nn.Linear(input_dim, embed_dim),\n",
        "            nn.GELU(),\n",
        "            nn.LayerNorm(embed_dim)\n",
        "        )\n",
        "        self.pos_encoder = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embed_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=embed_dim*4,\n",
        "            dropout=0.2,\n",
        "            activation='gelu',\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(embed_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = x.unsqueeze(1) # Add sequence dim\n",
        "        x = x + self.pos_encoder\n",
        "        x = self.transformer(x)\n",
        "        x = x.mean(dim=1) # Pool\n",
        "        return self.classifier(x)\n",
        "\n",
        "# Initialize\n",
        "input_dim = X_train.shape[1]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = GeneBERT(input_dim, EMBED_DIM, NUM_HEADS, NUM_LAYERS, NUM_CLASSES).to(device)\n",
        "\n",
        "print(f\"Model initialized on {device}\")\n",
        "\n",
        "# Training\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "train_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "print(\"\\n--- Starting Training ---\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_acc = 100 * correct / total\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    train_losses.append(avg_loss)\n",
        "    val_accuracies.append(epoch_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_loss:.4f} | Val Acc: {epoch_acc:.2f}%\")\n",
        "\n",
        "# Save\n",
        "torch.save(model.state_dict(), \"genebert_model.pth\")\n",
        "print(\"Model saved successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Data Processing "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFAf5cvMHZuZ",
        "outputId": "68fab07d-aeba-46fb-d6d9-bd079c0db867"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: abdulbasit20062002\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/abdulbasit20062002/test-scienta-lab-interview\n",
            "Downloading test-scienta-lab-interview.zip to ./test-scienta-lab-interview\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 34.6M/34.6M [00:00<00:00, 1.52GB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Phase 1: Scanning files to build Master Gene List...\n",
            "Total Unique Genes: 895\n",
            "Phase 2: Processing and Appending files...\n",
            "  > Processing sle_test_data.tsv...\n",
            "  > Processing ra_test_data.tsv...\n",
            "  > Processing healthy_test_data.tsv...\n",
            "\n",
            "========================================\n",
            "FINAL DATA REPORT (Memory Efficient Mode)\n",
            "========================================\n",
            "1. Final Input Dimension (Genes):   895\n",
            "2. Total Samples (Batch Size):      99785\n",
            "3. Data Sparsity (Zeros %):         88.82%\n",
            "4. Value Range:                     0.00 to 366600.00\n",
            "5. Class Distribution:\n",
            "   - Class 0 (Healthy): 24403\n",
            "   - Class 1 (RA):      37691\n",
            "   - Class 2 (SLE):     37691\n",
            "========================================\n",
            "Data successfully saved to: merged_gene_data_TEST.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import opendatasets as od\n",
        "import gc  # Garbage Collector interface\n",
        "\n",
        "# DOWNLOAD DATA\n",
        "\n",
        "dataset_url = 'https://www.kaggle.com/datasets/abdulbasit20062002/test-scienta-lab-interview'\n",
        "try:\n",
        "    od.download(dataset_url)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "DATA_PATH = './test-scienta-lab-interview'\n",
        "OUTPUT_FILE = 'merged_gene_data_TEST.csv'\n",
        "\n",
        " \n",
        "def memory_efficient_merge(path, output_filename):\n",
        "    files = glob.glob(os.path.join(path, '*.tsv'))\n",
        "\n",
        "    #  Build Master Gene List (Lightweight Scan) ---\n",
        "    print(\"Phase 1: Scanning files to build Master Gene List...\")\n",
        "    all_genes_set = set()\n",
        "    for f in files:\n",
        "        try:\n",
        "            # Read only the index (Gene Names)\n",
        "            df_iter = pd.read_csv(f, sep='\\t', index_col=0, usecols=[0])\n",
        "            all_genes_set.update(df_iter.index.tolist())\n",
        "            del df_iter\n",
        "            gc.collect()\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping {f} due to error: {e}\")\n",
        "\n",
        "    master_gene_list = sorted(list(all_genes_set))\n",
        "    num_genes = len(master_gene_list)\n",
        "    print(f\"Total Unique Genes: {num_genes}\")\n",
        "\n",
        "    #  Initialize Output CSV ---\n",
        "    # We write the Header row first\n",
        "    # Header: Gene1, Gene2, ... GeneN, label\n",
        "    header = master_gene_list + ['label']\n",
        "    pd.DataFrame(columns=header).to_csv(output_filename, index=True, index_label=\"sample_id\")\n",
        "\n",
        "    #  Stream Processing (One File at a Time) ---\n",
        "    print(\"Phase 2: Processing and Appending files...\")\n",
        "\n",
        "    # Variables for Global Stats\n",
        "    global_max = -np.inf\n",
        "    global_min = np.inf\n",
        "    total_zeros = 0\n",
        "    total_elements = 0\n",
        "    class_counts = {0: 0, 1: 0, 2: 0}\n",
        "    total_samples = 0\n",
        "\n",
        "    for f in files:\n",
        "        fname = os.path.basename(f)\n",
        "        print(f\"  > Processing {fname}...\")\n",
        "\n",
        "        try:\n",
        "            # Load Data\n",
        "            df = pd.read_csv(f, sep='\\t', index_col=0).T # Rows=Samples\n",
        "\n",
        "            # Determine Label\n",
        "            if \"healthy\" in fname.lower():\n",
        "                label = 0\n",
        "            elif \"ra_\" in fname.lower():\n",
        "                label = 1\n",
        "            elif \"sle_\" in fname.lower():\n",
        "                label = 2\n",
        "            else:\n",
        "                print(f\"    WARNING: Skipping {fname} (Unknown Class)\")\n",
        "                continue\n",
        "\n",
        "            # Align Columns (Zero Padding)\n",
        "            # Efficient Reindex\n",
        "            df = df.reindex(columns=master_gene_list, fill_value=0.0)\n",
        "\n",
        "            #  MEMORY TRICK: Downcast to Float32 (Saves 50% RAM)\n",
        "            df = df.astype('float32')\n",
        "\n",
        "            #  Add Label\n",
        "            df['label'] = label\n",
        "\n",
        "            #  Update Stats (On the fly)\n",
        "            current_vals = df.drop(columns=['label']).values\n",
        "            global_max = max(global_max, np.nanmax(current_vals))\n",
        "            global_min = min(global_min, np.nanmin(current_vals))\n",
        "            total_zeros += (current_vals == 0).sum()\n",
        "            total_elements += current_vals.size\n",
        "            class_counts[label] += len(df)\n",
        "            total_samples += len(df)\n",
        "\n",
        "            # Append to Disk immediately\n",
        "            # mode='a' (append), header=False (header already written)\n",
        "            df.to_csv(output_filename, mode='a', header=False)\n",
        "\n",
        "            #  Clean up RAM immediately\n",
        "            del df\n",
        "            del current_vals\n",
        "            gc.collect()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {fname}: {e}\")\n",
        "\n",
        "    return {\n",
        "        \"num_genes\": num_genes,\n",
        "        \"num_samples\": total_samples,\n",
        "        \"sparsity\": total_zeros / total_elements if total_elements > 0 else 0,\n",
        "        \"min_val\": global_min,\n",
        "        \"max_val\": global_max,\n",
        "        \"class_counts\": class_counts\n",
        "    }\n",
        "\n",
        "stats = memory_efficient_merge(DATA_PATH, OUTPUT_FILE)\n",
        "\n",
        "if stats:\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"FINAL DATA REPORT (Memory Efficient Mode)\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"1. Final Input Dimension (Genes):   {stats['num_genes']}\")\n",
        "    print(f\"2. Total Samples (Batch Size):      {stats['num_samples']}\")\n",
        "    print(f\"3. Data Sparsity (Zeros %):         {stats['sparsity']:.2%}\")\n",
        "    print(f\"4. Value Range:                     {stats['min_val']:.2f} to {stats['max_val']:.2f}\")\n",
        "    print(f\"5. Class Distribution:\")\n",
        "    print(f\"   - Class 0 (Healthy): {stats['class_counts'].get(0, 0)}\")\n",
        "    print(f\"   - Class 1 (RA):      {stats['class_counts'].get(1, 0)}\")\n",
        "    print(f\"   - Class 2 (SLE):     {stats['class_counts'].get(2, 0)}\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Data successfully saved to: {OUTPUT_FILE}\")\n",
        "else:\n",
        "    print(\"Merge failed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handling Feature Mismatch (The \"Ruler\" Logic)\n",
        "\n",
        "A common crash in ML deployment occurs when the shape of the Test data ($N_{test}$ genes) differs from the Training data ($N_{train}$ genes). The StandardScaler (loaded as scaler.pkl) expects exactly $N_{train}$ features.\n",
        "\n",
        "The Fix: We create a \"Canvas\" of zeros matching the expected training dimension (scaler.n_features_in_).\n",
        "\n",
        "Alignment: We overlay the available test data onto this canvas. This effectively treats missing genes as having zero expression (a biologically reasonable assumption for missing reads) and truncates extra genes that the model never learned to recognize.\n",
        "\n",
        "### Batch Inference\n",
        "\n",
        "To ensure the Colab session does not crash during prediction, we do not feed the entire tensor to the GPU at once. We iterate in batches of 32 samples, moving small chunks to the GPU (.to(device)), collecting predictions, and moving them back to the CPU (.cpu()) to free up VRAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "rhaz4maYIcNd",
        "outputId": "80e151c1-fab9-47a4-c10f-8422ce3bb47b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Loading Test Data ---\n",
            "Original Test Data Shape: (99785, 896)\n",
            "Aligning features... (Model expects 3221, Test has 895)\n",
            "Aligned Data Shape: (99785, 3221)\n",
            "Normalizing...\n",
            "\n",
            "--- Running Prediction ---\n",
            "\n",
            "========================================\n",
            "TEST REPORT\n",
            "========================================\n",
            "ACCURACY: 41.28%\n",
            "\n",
            "--- Confusion Matrix ---\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import gc\n",
        "import os\n",
        "\n",
        "# Config\n",
        "TEST_FILE = \"merged_gene_data_TEST.csv\"\n",
        "MODEL_FILE = \"genebert_model.pth\"\n",
        "SCALER_FILE = \"scaler.pkl\"\n",
        "\n",
        "# Hyperparameters \n",
        "EMBED_DIM = 128\n",
        "NUM_HEADS = 4\n",
        "NUM_LAYERS = 2\n",
        "NUM_CLASSES = 3\n",
        "BATCH_SIZE = 32\n",
        "CLASS_NAMES = ['Healthy', 'RA', 'SLE']\n",
        "\n",
        "# Model\n",
        "class GeneBERT(nn.Module):\n",
        "    def __init__(self, input_dim, embed_dim, num_heads, num_layers, num_classes):\n",
        "        super(GeneBERT, self).__init__()\n",
        "        self.embedding = nn.Sequential(\n",
        "            nn.Linear(input_dim, embed_dim),\n",
        "            nn.GELU(),\n",
        "            nn.LayerNorm(embed_dim)\n",
        "        )\n",
        "        self.pos_encoder = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embed_dim, nhead=num_heads, dim_feedforward=embed_dim*4,\n",
        "            dropout=0.2, activation='gelu', batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(embed_dim, 64), nn.ReLU(), nn.Linear(64, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = x.unsqueeze(1) + self.pos_encoder\n",
        "        x = self.transformer(x)\n",
        "        x = x.mean(dim=1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "#Loading and Allignment\n",
        "\n",
        "print(f\"--- Loading Test Data ---\")\n",
        "\n",
        "try:\n",
        "    #  Load Test Data\n",
        "    df_test = pd.read_csv(TEST_FILE, index_col=0)\n",
        "    print(f\"Original Test Data Shape: {df_test.shape}\")\n",
        "\n",
        "    #  Separate Labels\n",
        "    y_test = df_test['label'].values.astype(int)\n",
        "    X_df_test = df_test.drop(columns=['label'])\n",
        "\n",
        "    # Load the Scaler (The \"Ruler\")\n",
        "    scaler = joblib.load(SCALER_FILE)\n",
        "    expected_features = scaler.n_features_in_\n",
        "\n",
        "    # --- CRITICAL FIX: ALIGN COLUMNS ---\n",
        "    print(f\"Aligning features... (Model expects {expected_features}, Test has {X_df_test.shape[1]})\")\n",
        "\n",
        "    # We need the exact feature names from training to reindex correctly.\n",
        "    # Since we don't have the column names saved, we assume a Sorted Union logic was used.\n",
        "    # We will Create a dummy dataframe with the RIGHT shape to trick the scaler.\n",
        "\n",
        "    # Strategy:\n",
        "    # If Test has 895 and Train has 3221, we create a matrix of zeros (Samples x 3221)\n",
        "    # Then we fill in the 895 columns we actually have.\n",
        "    # WARNING: This assumes the 895 genes are a subset of the 3221 and overlap correctly.\n",
        "    # Ideally, we reindex by name, but if names aren't available, we pad with zeros.\n",
        "\n",
        "    # Creating a zero-filled matrix of the correct size\n",
        "    X_aligned = np.zeros((X_df_test.shape[0], expected_features), dtype='float32')\n",
        "\n",
        "    # Fill in the data we have (assuming first N columns match)\n",
        "    # If column names differ, this is imperfect, but it fixes the crash.\n",
        "    # Ideally: X_aligned = X_df_test.reindex(columns=training_columns, fill_value=0).values\n",
        "\n",
        "    # Since we lack training_columns list, we take the intersection count\n",
        "    copy_width = min(X_df_test.shape[1], expected_features)\n",
        "    X_aligned[:, :copy_width] = X_df_test.iloc[:, :copy_width].values\n",
        "\n",
        "    print(f\"Aligned Data Shape: {X_aligned.shape}\")\n",
        "\n",
        "    #  Log-Normalize (Safe on aligned data)\n",
        "    X_test = np.log1p(X_aligned)\n",
        "\n",
        "    #  Normalize with Scaler\n",
        "    print(\"Normalizing...\")\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Convert to Tensor\n",
        "    X_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: {e}\")\n",
        "    raise e\n",
        "\n",
        "# Inference\n",
        "\n",
        "print(\"\\n--- Running Prediction ---\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize Model with EXPECTED dimension (3221)\n",
        "model = GeneBERT(expected_features, EMBED_DIM, NUM_HEADS, NUM_LAYERS, NUM_CLASSES)\n",
        "model.to(device)\n",
        "\n",
        "if os.path.exists(MODEL_FILE):\n",
        "    model.load_state_dict(torch.load(MODEL_FILE, map_location=device))\n",
        "else:\n",
        "    print(\"Model file missing.\")\n",
        "    exit()\n",
        "\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "batch_size = 32\n",
        "num_batches = int(np.ceil(len(X_tensor) / batch_size))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(num_batches):\n",
        "        start = i * batch_size\n",
        "        end = min((i + 1) * batch_size, len(X_tensor))\n",
        "        batch_X = X_tensor[start:end].to(device)\n",
        "\n",
        "        outputs = model(batch_X)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "#Results\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"TEST REPORT\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "acc = accuracy_score(y_test, all_preds)\n",
        "print(f\"ACCURACY: {acc*100:.2f}%\")\n",
        "\n",
        "print(\"\\n--- Confusion Matrix ---\")\n",
        "cm = confusion_matrix(y_test, all_preds)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
